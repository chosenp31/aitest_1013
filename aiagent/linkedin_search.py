# aiagent/linkedin_search.py
# LinkedInå€™è£œè€…æ¤œç´¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ¤œç´¢æ¡ä»¶ã‚’æŸ”è»Ÿã«è¨­å®šå¯èƒ½ï¼‰

import os
import csv
import time
import pickle
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager

# ==============================
# è¨­å®š
# ==============================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")
OUTPUT_FILE = os.path.join(DATA_DIR, "candidates_raw.csv")
COOKIE_FILE = os.path.join(DATA_DIR, "cookies.pkl")

os.makedirs(DATA_DIR, exist_ok=True)

# ==============================
# ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆè‡ªå‹•/æ‰‹å‹•ï¼‰
# ==============================
def login():
    """LinkedInã«ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆCookieä¿å­˜ã§2å›ç›®ä»¥é™ã¯è‡ªå‹•ï¼‰"""

    options = Options()
    options.add_argument("--start-maximized")
    options.add_argument("--disable-notifications")
    options.add_experimental_option("detach", True)

    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    # Cookieä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèª
    if os.path.exists(COOKIE_FILE):
        print("ğŸ”‘ ä¿å­˜ã•ã‚ŒãŸCookieã‚’ä½¿ç”¨ã—ã¦è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³ä¸­...")

        # ã¾ãšLinkedInã«ã‚¢ã‚¯ã‚»ã‚¹ï¼ˆCookieã‚’è¨­å®šã™ã‚‹ãŸã‚ï¼‰
        driver.get("https://www.linkedin.com")
        time.sleep(2)

        # Cookieã‚’èª­ã¿è¾¼ã¿
        try:
            with open(COOKIE_FILE, "rb") as f:
                cookies = pickle.load(f)

            for cookie in cookies:
                try:
                    driver.add_cookie(cookie)
                except Exception:
                    # ç„¡åŠ¹ãªCookieã¯ã‚¹ã‚­ãƒƒãƒ—
                    pass

            # Cookieã‚’è¨­å®šå¾Œã€å†åº¦ã‚¢ã‚¯ã‚»ã‚¹
            driver.get("https://www.linkedin.com/feed")
            time.sleep(5)  # å¾…æ©Ÿæ™‚é–“ã‚’å»¶é•·

            # ç¾åœ¨ã®URLã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            current_url = driver.current_url
            print(f"   ğŸ“ ç¾åœ¨ã®URL: {current_url}")

            # ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸç¢ºèªï¼ˆã‚ˆã‚Šå³å¯†ã«ï¼‰
            if ("feed" in current_url or "home" in current_url) and "login" not in current_url:
                print("âœ… è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³æˆåŠŸï¼")
                return driver
            else:
                print("âš ï¸ CookieãŒæœŸé™åˆ‡ã‚Œã€ã¾ãŸã¯ç„¡åŠ¹ã§ã™ã€‚æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
                print(f"   ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆå…ˆ: {current_url}")
                os.remove(COOKIE_FILE)  # å¤ã„Cookieã‚’å‰Šé™¤

        except Exception as e:
            print(f"âš ï¸ Cookieèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            print("   æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™...")
            if os.path.exists(COOKIE_FILE):
                os.remove(COOKIE_FILE)

    # æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³
    print("ğŸ”‘ LinkedIn æ‰‹å‹•ãƒ­ã‚°ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰é–‹å§‹...")
    driver.get("https://www.linkedin.com/login")
    print("ğŸŒ ã”è‡ªèº«ã§LinkedInã«ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ãã ã•ã„...")
    print("ğŸ’¡ ãƒ­ã‚°ã‚¤ãƒ³å¾Œã€feedãƒšãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã‚‹ã¾ã§å¾…æ©Ÿã—ã¾ã™...")

    # ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†å¾…æ©Ÿ
    while ("feed" not in driver.current_url) and ("home" not in driver.current_url):
        time.sleep(1.5)

    print("âœ… ãƒ­ã‚°ã‚¤ãƒ³å®Œäº†ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")

    # Cookieã‚’ä¿å­˜
    try:
        cookies = driver.get_cookies()
        with open(COOKIE_FILE, "wb") as f:
            pickle.dump(cookies, f)
        print(f"ğŸ’¾ Cookieã‚’ä¿å­˜ã—ã¾ã—ãŸ: {COOKIE_FILE}")
        print("   æ¬¡å›ã‹ã‚‰è‡ªå‹•ãƒ­ã‚°ã‚¤ãƒ³ãŒä½¿ç”¨ã•ã‚Œã¾ã™ã€‚")
    except Exception as e:
        print(f"âš ï¸ Cookieä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    return driver

# ==============================
# ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æŠ½å‡º
# ==============================
def extract_profiles(driver):
    """ç¾åœ¨è¡¨ç¤ºä¸­ã®æ¤œç´¢çµæœãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’æŠ½å‡º"""

    # ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’å–å¾—ã™ã‚‹JavaScript
    script = """
    function extractProfiles() {
        const results = [];
        const seen = new Set();

        // æ¤œç´¢çµæœã®ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚’å–å¾—ï¼ˆè¤‡æ•°ã®æˆ¦ç•¥ã‚’è©¦ã™ï¼‰
        let items = [];

        // æˆ¦ç•¥1: æ–°ã—ã„ã‚¯ãƒ©ã‚¹åï¼ˆ2025å¹´1æœˆæ™‚ç‚¹ï¼‰
        items = document.querySelectorAll('li.qTpSkRrerBcUqHivKtVbqVGnMhgMkDU');
        console.log('æˆ¦ç•¥1ï¼ˆæ–°ã‚¯ãƒ©ã‚¹åï¼‰:', items.length, 'ä»¶');

        // æˆ¦ç•¥2: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - æ¤œç´¢çµæœã®ulå†…ã®liè¦ç´ 
        if (items.length === 0) {
            const ul = document.querySelector('ul.gXgHtWXGAynxZWGGYQtgBMtLnHWPyXyPsSuyEH');
            if (ul) {
                items = ul.querySelectorAll('li');
                console.log('æˆ¦ç•¥2ï¼ˆulå†…ã®liï¼‰:', items.length, 'ä»¶');
            }
        }

        // æˆ¦ç•¥3: ã•ã‚‰ãªã‚‹ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ - ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãƒªãƒ³ã‚¯ã‹ã‚‰è¦ªã®liã‚’å–å¾—
        if (items.length === 0) {
            const profileLinks = document.querySelectorAll('a[href*="/in/"]');
            const liSet = new Set();
            profileLinks.forEach(link => {
                let current = link;
                for (let i = 0; i < 10; i++) {
                    current = current.parentElement;
                    if (!current) break;
                    if (current.tagName === 'LI') {
                        liSet.add(current);
                        break;
                    }
                }
            });
            items = Array.from(liSet);
            console.log('æˆ¦ç•¥3ï¼ˆãƒªãƒ³ã‚¯ã‹ã‚‰è¦ªliï¼‰:', items.length, 'ä»¶');
        }

        items.forEach(item => {
            try {
                // ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«URL
                const profileLink = item.querySelector('a[href*="/in/"]');
                if (!profileLink) return;

                const url = profileLink.href.split('?')[0];
                if (seen.has(url)) return;
                seen.add(url);

                // åå‰ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è©¦ã™ï¼‰
                let name = '';
                const nameEl1 = item.querySelector('span[aria-hidden="true"]');
                const nameEl2 = item.querySelector('span.entity-result__title-text span[dir="ltr"]');
                const nameEl3 = profileLink.querySelector('span[dir="ltr"]');
                name = (nameEl1 || nameEl2 || nameEl3)?.textContent.trim() || '';

                // è¦‹å‡ºã—ï¼ˆè·ç¨®ãƒ»å½¹è·ï¼‰
                const headlineEl = item.querySelector('.entity-result__primary-subtitle, [class*="primary-subtitle"]');
                const headline = headlineEl ? headlineEl.textContent.trim() : '';

                // ä¼šç¤¾ãƒ»å­¦æ ¡
                const secondaryEl = item.querySelector('.entity-result__secondary-subtitle, [class*="secondary-subtitle"]');
                const secondary = secondaryEl ? secondaryEl.textContent.trim() : '';

                // å ´æ‰€
                const locationEl = item.querySelector('.entity-result__location, [class*="location"]');
                const location = locationEl ? locationEl.textContent.trim() : '';

                if (name && url) {
                    results.push({
                        name: name,
                        url: url,
                        headline: headline,
                        company: secondary,
                        location: location
                    });
                }
            } catch (e) {
                console.error('Error extracting profile:', e);
            }
        });

        console.log('æœ€çµ‚æŠ½å‡ºä»¶æ•°:', results.length, 'ä»¶');
        return results;
    }
    return extractProfiles();
    """

    try:
        return driver.execute_script(script) or []
    except Exception as e:
        print(f"âš ï¸ ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return []

# ==============================
# ãƒšãƒ¼ã‚¸ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«
# ==============================
def scroll_page(driver):
    """ãƒšãƒ¼ã‚¸ã‚’ä¸‹ã¾ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«"""
    last_height = 0
    for _ in range(5):
        driver.find_element(By.TAG_NAME, "body").send_keys(Keys.END)
        time.sleep(2.0)
        new_height = driver.execute_script("return document.body.scrollHeight")
        if new_height == last_height:
            break
        last_height = new_height

# ==============================
# ãƒ¡ã‚¤ãƒ³æ¤œç´¢å‡¦ç†
# ==============================
def search_candidates(keywords, location="Japan", max_pages=3):
    """
    LinkedInå€™è£œè€…æ¤œç´¢

    Args:
        keywords: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¾‹: "SIer OR ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ OR ITã‚³ãƒ³ã‚µãƒ«"ï¼‰
        location: åœ°åŸŸï¼ˆä¾‹: "Japan", "æ±äº¬"ï¼‰
        max_pages: æ¤œç´¢ã™ã‚‹ãƒšãƒ¼ã‚¸æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ3ï¼‰

    Returns:
        æŠ½å‡ºã—ãŸå€™è£œè€…æ•°
    """

    driver = login()

    # æ¤œç´¢URLã‚’æ§‹ç¯‰
    search_url = f"https://www.linkedin.com/search/results/people/?keywords={keywords}&origin=GLOBAL_SEARCH_HEADER"
    if location:
        search_url += f"&location={location}"

    print(f"\nğŸ” æ¤œç´¢æ¡ä»¶:")
    print(f"   ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}")
    print(f"   åœ°åŸŸ: {location}")
    print(f"   ãƒšãƒ¼ã‚¸æ•°: {max_pages}")
    print(f"\nğŸ”— æ¤œç´¢URL: {search_url}")

    driver.get(search_url)

    # ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿å¾…æ©Ÿ
    wait = WebDriverWait(driver, 20)
    try:
        wait.until(lambda d: d.execute_script("return document.readyState") == "complete")
    except TimeoutException:
        print("âš ï¸ ãƒšãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")

    all_candidates = []
    seen_urls = set()

    for page in range(1, max_pages + 1):
        print(f"\n{'='*70}")
        print(f"ğŸ“„ ãƒšãƒ¼ã‚¸ {page}/{max_pages} ã‚’å‡¦ç†ä¸­...")
        print(f"{'='*70}")

        time.sleep(3.0)
        scroll_page(driver)
        time.sleep(2.0)

        # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æŠ½å‡º
        profiles = extract_profiles(driver)
        print(f"ğŸ“¦ æŠ½å‡ºä»¶æ•°: {len(profiles)} ä»¶")

        # é‡è¤‡é™¤å¤–ã—ã¦è¿½åŠ 
        new_count = 0
        for profile in profiles:
            url = profile.get("url", "")
            if url and url not in seen_urls:
                seen_urls.add(url)
                all_candidates.append(profile)
                new_count += 1

        print(f"âœ… æ–°è¦å€™è£œè€…: {new_count} ä»¶ï¼ˆç´¯è¨ˆ: {len(all_candidates)} ä»¶ï¼‰")

        # æ¬¡ãƒšãƒ¼ã‚¸ã¸
        if page < max_pages:
            try:
                # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ã‚’æ¢ã™ï¼ˆã€Œ1æ¬¡ã€ã€Œ2æ¬¡ã€ãªã©ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒœã‚¿ãƒ³ã¨åŒºåˆ¥ï¼‰
                # æˆ¦ç•¥1: ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒªã‚¢å†…ã®ãƒœã‚¿ãƒ³ã«é™å®š
                next_btn = None
                try:
                    next_btn = driver.find_element(
                        By.XPATH,
                        "//div[contains(@class, 'artdeco-pagination')]//button[contains(@aria-label, 'æ¬¡') or contains(@aria-label, 'Next')]"
                    )
                    print("   âœ“ æˆ¦ç•¥1: ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒªã‚¢å†…ã®ãƒœã‚¿ãƒ³ã‚’æ¤œå‡º")
                except NoSuchElementException:
                    pass

                # æˆ¦ç•¥2: aria-labelãŒã€Œæ¬¡ã¸ã€ã§å§‹ã¾ã‚‹ãƒœã‚¿ãƒ³
                if not next_btn:
                    try:
                        next_btn = driver.find_element(
                            By.XPATH,
                            "//button[starts-with(@aria-label, 'æ¬¡ã¸') or starts-with(@aria-label, 'Next')]"
                        )
                        print("   âœ“ æˆ¦ç•¥2: aria-labelå‰æ–¹ä¸€è‡´ã§æ¤œå‡º")
                    except NoSuchElementException:
                        pass

                # æˆ¦ç•¥3: ãƒšãƒ¼ã‚¸ä¸‹éƒ¨ã®ãƒœã‚¿ãƒ³ã®ã¿ï¼ˆä¸Šéƒ¨ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é™¤å¤–ï¼‰
                if not next_btn:
                    buttons = driver.find_elements(
                        By.XPATH,
                        "//button[contains(@aria-label, 'æ¬¡') or contains(@aria-label, 'Next')]"
                    )
                    # Yåº§æ¨™ãŒå¤§ãã„ï¼ˆãƒšãƒ¼ã‚¸ä¸‹éƒ¨ï¼‰ã®ãƒœã‚¿ãƒ³ã‚’é¸æŠ
                    if buttons:
                        next_btn = max(buttons, key=lambda btn: btn.location['y'])
                        print("   âœ“ æˆ¦ç•¥3: ãƒšãƒ¼ã‚¸ä¸‹éƒ¨ã®ãƒœã‚¿ãƒ³ã‚’æ¤œå‡º")

                if next_btn:
                    driver.execute_script("arguments[0].scrollIntoView(true);", next_btn)
                    time.sleep(1.0)
                    next_btn.click()
                    print("â¡ï¸ æ¬¡ãƒšãƒ¼ã‚¸ã¸é·ç§»...")
                    time.sleep(4.0)
                else:
                    print("âš ï¸ æ¬¡ãƒšãƒ¼ã‚¸ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢çµ‚äº†ã€‚")
                    break

            except NoSuchElementException:
                print("âš ï¸ æ¬¡ãƒšãƒ¼ã‚¸ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ¤œç´¢çµ‚äº†ã€‚")
                break

    # CSVä¿å­˜
    print(f"\n{'='*70}")
    print(f"ğŸ“Š æ¤œç´¢å®Œäº†ã‚µãƒãƒªãƒ¼")
    print(f"{'='*70}")
    print(f"ç·å€™è£œè€…æ•°: {len(all_candidates)} ä»¶")
    print(f"ä¿å­˜å…ˆ: {OUTPUT_FILE}")

    with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as f:
        fieldnames = ["name", "url", "headline", "company", "location"]
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(all_candidates)

    print(f"âœ… å€™è£œè€…ãƒªã‚¹ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    print(f"\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: python3 aiagent/linkedin_scorer.py ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ")

    return len(all_candidates)

# ==============================
# ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# ==============================
if __name__ == "__main__":
    import sys

    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã‹ã‚‰æ¤œç´¢æ¡ä»¶ã‚’å–å¾—
    if len(sys.argv) > 1:
        keywords = sys.argv[1]
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: è¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ORæ¤œç´¢
        keywords = "SIer OR ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ OR ITã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆ OR ITã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ OR DXã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"

    location = sys.argv[2] if len(sys.argv) > 2 else "Japan"
    max_pages = int(sys.argv[3]) if len(sys.argv) > 3 else 3

    search_candidates(keywords, location, max_pages)
